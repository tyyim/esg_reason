# Notion Research Proposal Update - 2025-10-07

## üö® Critical Update: Dataset Split Corrected

### Issue Found
- **Previous implementation used WRONG split**: 80% train / 10% dev / 10% test
- **Baseline evaluation on 746 questions was INVALID** (should have been ~187 questions)
- **Result**: 55.8% accuracy on wrong split needs to be discarded

### Correction Applied
- **Fixed to correct split**: 20% train / 10% dev / 70% test
- **New split sizes**:
  - Train: 186 questions (20%)
  - Dev: 93 questions (10%)
  - Test: 654 questions (70%)
  - Total: 933 questions

### Impact
- ‚úÖ All 45 documents indexed to PostgreSQL (54,608 chunks)
- ‚ùå Previous 55.8% baseline is invalid (wrong split)
- ‚è≥ Need to re-establish baseline on correct 186 questions
- ‚úÖ MIPROv2 architecture documented and ready

---

## üìä Current Project Status

### ‚úÖ Completed
1. **Document Indexing**: All 45/45 documents ‚Üí PostgreSQL + pgvector
   - Embeddings: Qwen text-embedding-v4 (1024-dim)
   - Total chunks: 54,608
   - Documents: 100% coverage including IPCC AR6 WG3

2. **Dataset Split Fixed**: Corrected from 80/10/10 to 20/10/70
   - Train: 186 questions for optimization
   - Dev: 93 questions for validation
   - Test: 654 questions for final eval

3. **MIPROv2 Architecture Documented**: Complete diagram created
   - Meta-optimizer: Qwen Max proposes better prompts
   - Student model: Qwen Max executes RAG with optimized prompts
   - Two-stage reasoning: ChainOfThought ‚Üí Answer Extraction
   - See: `MIPROv2_Architecture_Diagram.md`

### ‚è≥ In Progress
1. **Baseline Re-Establishment**: Need to evaluate on correct 186 questions
   - Previous: 55.8% on 746 questions (invalid)
   - Target: Establish legitimate baseline on 20% split

2. **MIPROv2 Optimization Ready**: Implementation complete, awaiting baseline
   - Script: `dspy_implementation/miprov2_qwen_optimization.py`
   - Configuration: 10 candidates, 20 trials, 4 few-shot examples
   - Estimated runtime: 45-83 minutes total

### üéØ Next Steps
1. **Option 1 (Recommended)**: Skip baseline re-evaluation, proceed directly to MIPROv2
   - MIPROv2 will establish its own baseline during optimization
   - More efficient: Combines baseline + optimization in one run

2. **Option 2**: Explicitly re-run baseline on 186 questions first
   - Provides exact baseline number for comparison
   - Takes ~10-15 minutes before optimization

---

## üîß Technical Architecture

### MIPROv2 Two-Stage Approach

**Current Baseline** (default prompts):
```
Question ‚Üí PostgreSQL Retrieval (Top-5 chunks)
  ‚Üì
Stage 1: ChainOfThought Reasoning (Qwen Max)
  ‚Ä¢ Instruction: "Analyze context and provide detailed reasoning"
  ‚Üì
Stage 2: Answer Extraction (Qwen Max)
  ‚Ä¢ Instruction: "Extract final answer in specified format"
  ‚Üì
Answer (evaluated with MMESGBench fuzzy matching)
```

**MIPROv2 Optimization Process**:
```
Step 1: Baseline evaluation (default prompts on 186 questions)
  ‚Üì
Step 2: Qwen Max proposes 10 candidate instructions
  ‚Ä¢ Better reasoning strategies
  ‚Ä¢ Better extraction techniques
  ‚Üì
Step 3: Test each candidate on training subset
  ‚Ä¢ 20 trials with different combinations
  ‚Ä¢ Track best-performing instructions
  ‚Üì
Step 4: Optimize few-shot demonstrations (optional)
  ‚Ä¢ 4 auto-generated examples
  ‚Ä¢ 4 labeled examples
  ‚Üì
Step 5: Final optimized module
  ‚Ä¢ Better ESGReasoning instruction
  ‚Ä¢ Better AnswerExtraction instruction
  ‚Ä¢ Evaluated on dev set (93 questions)
```

### Key Architectural Insight
- **Same LLM (Qwen Max) plays two roles**:
  1. **Meta-optimizer**: Proposes better prompts via MIPROv2
  2. **Student model**: Executes RAG pipeline with those prompts
- **This is valid and common in DSPy**
- **Distinction**: What the LLM is doing, not which LLM is used

---

## üìà Expected Performance

### Baseline (to be established)
- Train set (186 questions): TBD
- Expected: Similar to previous ~55-60% range
- Method: PostgreSQL + Qwen embeddings with DEFAULT prompts

### MIPROv2 Target
- Dev set (93 questions): Baseline + 1-2% absolute improvement
- Method: OPTIMIZED prompts generated by MIPROv2
- Example improvements:
  - Better handling of tables/charts
  - More precise numerical extraction
  - Improved list completeness
  - Format validation

### Test Set (Final)
- Test set (654 questions): Final evaluation after optimization
- This will be the published result
- Comparison: Baseline vs MIPROv2 optimized

---

## üìù Files to Sync with Notion

### New Files Created
1. `MIPROv2_Architecture_Diagram.md` - Complete architecture documentation
2. `dspy_implementation/miprov2_qwen_optimization.py` - Optimization script
3. `dspy_implementation/dspy_dataset.py` - Fixed to 20/10/70 split
4. `mmesg_indexing_checkpoint.json` - All 45 documents indexed
5. `qwen_baseline_train_results.json` - Invalid results (wrong split)

### Updated Files
- `README.md` - Corrected splits, updated Phase 1a tasks
- `dspy_implementation/dspy_dataset.py` - Changed default to 20/10/70

### Files to Archive
- `qwen_baseline_train_results.json` - Mark as "incorrect split"
- `qwen_baseline_train_checkpoint.json` - Mark as "incorrect split"

---

## üéØ Decision Point for Notion Discussion

**Question**: How to proceed with MIPROv2 optimization?

**Option 1: Direct Optimization (Recommended)**
- ‚úÖ More efficient: One combined run
- ‚úÖ MIPROv2 establishes baseline automatically
- ‚úÖ Faster time-to-results (~45-60 minutes total)
- ‚ùå Don't get explicit standalone baseline number

**Option 2: Explicit Baseline First**
- ‚úÖ Get clean baseline number for reporting
- ‚úÖ Clear before/after comparison
- ‚ùå Extra 10-15 minutes before optimization
- ‚ùå Two separate runs (more manual work)

**Recommendation**: Option 1 - Proceed directly to MIPROv2
- The optimization process will show improvement clearly
- Dev set results provide the comparison point
- More efficient research workflow

---

## üìä Summary for Notion Research Proposal

### Update Section: "Phase 1a - MIPROv2 Optimization"

**Status**: Ready to execute (dataset split corrected)

**Key Changes**:
- ‚úÖ Dataset split corrected to 20/10/70 (was incorrectly 80/10/10)
- ‚úÖ All 45 documents indexed to PostgreSQL (54,608 chunks)
- ‚úÖ MIPROv2 architecture fully documented
- ‚è≥ Previous 55.8% baseline invalid (wrong split), needs re-establishment
- ‚è≥ Ready to run MIPROv2 optimization (~45-60 minutes)

**Expected Outcome**:
- Baseline: TBD on 186 questions (20% split)
- Target: Baseline + 1-2% via optimized prompts
- Method: MIPROv2 proposes better instructions for two-stage reasoning
- Evaluation: MMESGBench fuzzy matching (100% compatible)

**Timeline**:
- Optimization: ~45-60 minutes
- Dev set evaluation: ~5-8 minutes
- Total: Can complete today

---

**Generated**: 2025-10-07
**Next Action**: Approve Option 1 or 2, then launch MIPROv2 optimization
**Key Documents**: `MIPROv2_Architecture_Diagram.md`, `README.md`, `CLAUDE.md`
