"""Prompt templates adapted from the ACE paper for reuse."""

# GENERATOR_PROMPT = """\
# You are an expert assistant that must solve the task using the provided playbook of strategies.
# Apply relevant bullets, avoid known mistakes, and show step-by-step reasoning.

# Playbook:
# {playbook}

# Recent reflection:
# {reflection}

# Question:
# {question}

# Additional context:
# {context}

# Respond with a compact JSON object:
# {{
#   "reasoning": "<step-by-step chain of thought>",
#   "bullet_ids": ["<id1>", "<id2>", "..."],
#   "final_answer": "<concise final answer>"
# }}
# """


# REFLECTOR_PROMPT = """\
# You are a senior reviewer diagnosing the generator's trajectory.
# Use the playbook, model reasoning, and feedback to identify mistakes and actionable insights.
# Output must be a single valid JSON object. Do NOT include analysis text or explanations outside the JSON.
# Begin the response with `{{` and end with `}}`.

# Question:
# {question}
# Model reasoning:
# {reasoning}
# Model prediction: {prediction}
# Ground truth (if available): {ground_truth}
# Feedback: {feedback}
# Playbook excerpts consulted:
# {playbook_excerpt}

# Return JSON:
# {{
#   "reasoning": "<analysis>",
#   "error_identification": "<what went wrong>",
#   "root_cause_analysis": "<why it happened>",
#   "correct_approach": "<what should be done>",
#   "key_insight": "<reusable takeaway>",
#   "bullet_tags": [
#     {{"id": "<bullet-id>", "tag": "helpful|harmful|neutral"}}
#   ]
# }}
# """


# CURATOR_PROMPT = """\
# You are the curator of the ACE playbook. Merge the latest reflection into structured updates.
# Only add genuinely new material. Do not regenerate the entire playbook.
# Respond with a single valid JSON object onlyâ€”no analysis or extra narration.

# Training progress: {progress}
# Playbook stats: {stats}

# Recent reflection:
# {reflection}

# Current playbook:
# {playbook}

# Question context:
# {question_context}

# Respond with JSON:
# {{
#   "reasoning": "<how you decided on the updates>",
#   "operations": [
#     {{
#       "type": "ADD|UPDATE|TAG|REMOVE",
#       "section": "<section name>",
#       "content": "<bullet text>",
#       "bullet_id": "<optional existing id>",
#       "metadata": {{"helpful": 1, "harmful": 0}}
#     }}
#   ]
# }}
# If no updates are required, return an empty list for "operations".
# """

# GENERATOR_PROMPT = """\
# You are an ESG (Environmental, Social, Governance) reasoning assistant. Answer questions about corporate ESG reports using retrieved document context and accumulated insights from the playbook.
# We will provide you with a playbook of strategies and you can refer to it to generate the analysis. If the playbook is empty, you can still answer the question based on the context and your knowledge.
# Apply relevant bullets, avoid known mistakes, and show step-by-step reasoning.

# Format Guidelines:
# - **Int**: Return only the integer number (e.g., "42")
# - **Float**: Return the number with appropriate decimal precision (e.g., "3.14" or "10.5")
# - **Str**: Return the exact text string as it appears in the context (e.g., "Scope 1 emissions")
# - **List**: Return a valid JSON array (e.g., ["item1", "item2", "item3"])

# Important Notes:
# - For calculations: Show your work but provide ONLY the final answer
# - For lists: Ensure proper JSON formatting with quotes and brackets
# - For text: Match the exact terminology from the document

# Playbook:
# {playbook}

# Recent reflection:
# {reflection}

# ESG question to answer:
# {question}

# Retrieved chunks from ESG documents:
# {context}

# Required answer format: Int, Float, Str, or List:
# {answer_format}

# Respond with a compact JSON object:
# {{
#   "reasoning": "<step-by-step chain of thought>",
#   "bullet_ids": ["<id1>", "<id2>", "..."],
#   "final_answer": "Concise final answer in specified format, or "Not answerable" if analysis mentions that the question cannot be answered from the context"
# }}
# """

GENERATOR_PROMPT = """\
You are an ESG (Environmental, Social, Governance) analyst. Answer the following question based ONLY on the provided context from an ESG report.
We will provide you with a playbook of strategies and you can refer to it to generate the analysis. If the playbook is empty, you can still answer the question based on the context and your knowledge.
Apply relevant bullets, avoid known mistakes, and show step-by-step reasoning.

Context from ESG Report: {context}

Question: {question}

Expected Final Answer Format <Int, Float, Str, List, null>: {answer_format}

Playbook: {playbook}

Recent reflection: {reflection}

Instructions:
- For Int: Return the integer number (e.g., "5") 
- For Float: Return the number with appropriate decimal precision (e.g., "3.14" or "10.5" or "10")
- For Str: Return the final and concise answer from your analysis (e.g., "Seller reports Scope 1, buyer reports Scope 2")
- For List: Return the valid JSON array format (e.g., '[\"Africa\", \"Asia\"]')
- For null: Return 'Not answerable' if the question cannot be answered from the context and the question

Important Notes:
- For calculations: Show your calculation and reasoning steps but provide ONLY the final answer in the final_answer field
- For lists: Ensure proper JSON formatting with quotes and brackets
- For text: Match the exact terminology from the document

Respond with a compact JSON object:
{{
  "reasoning": "Detailed reasoning and analysis based on the provided context. Should explain the answer and reference specific information from the context. If context lacks sufficient information, clearly state the question cannot be answered.",
  "bullet_ids": ["<id1>", "<id2>", "..."],
  "final_answer": "Final answer in specified format"
}}
"""

REFLECTOR_PROMPT = """\
You are an expert analyst and educator. Your job is to diagnose why a model's reasoning went wrong by analyzing the gap between predicted answer and the ground truth.
Instructions: 
- Carefully analyze the model's reasoning trace to identify where it went wrong 
- Take the environment feedback into account, comparing the predicted answer with the ground truth to understand the gap 
- Identify specific conceptual errors, calculation mistakes, or misapplied strategies 
- Provide actionable insights that could help the model avoid this mistake in the future 
- Focus on the root cause, not just surface-level errors 
- Be specific about what the model should have done differently 
- You will receive bulletpoints that are part of playbook that's used by the generator to answer the question. 
- You need to analyze these bulletpoints, and give the tag for each bulletpoint, tag can be ['helpful', 'harmful', 'neutral'] (for the generator to generate the correct answer)

Your output should be a json object, which contains the following fields 
- reasoning: your chain of thought / reasoning / thinking process, detailed analysis and calculations 
- error_identification: what specifically went wrong in the reasoning? 
- root_cause_analysis: why did this error occur? What concept was misunderstood? 
- correct_approach: what should the model have done instead? 
- key_insight: what strategy, formula, or principle should be remembered to avoid this error? 
- bullet_tags: a list of json objects with bullet_id and tag for each bulletpoint used by the generator
Output must be a single valid JSON object. Do NOT include analysis text or explanations outside the JSON.
Begin the response with `{{` and end with `}}`.

Question:
{question}

Model reasoning:
{reasoning}

Model prediction: {prediction}

Ground truth (if available): {ground_truth}

Evaluation Feedback: {feedback}

Part of Playbook that's used by the generator to answer the question:
{playbook_excerpt}

Return JSON:
{{
  "reasoning": "<Your chain of thought / reasoning / thinking process, detailed analysis and calculations>",
  "error_identification": "<What specifically went wrong in the reasoning?>",
  "root_cause_analysis": "<Why did this error occur? What concept was misunderstood?>",
  "correct_approach": "<What should the model have done instead?>",
  "key_insight": "<What strategy, formula, or principle should be remembered to avoid this error?>",
  "bullet_tags": [
    {{"id": "<bullet-id>", "tag": "helpful|harmful|neutral"}}
  ]
}}
"""


CURATOR_PROMPT = """\
You are a master curator of knowledge. Your job is to identify what new insights should be added to an existing playbook based on a
reflection from a previous attempt.
Context: 
- The playbook you created will be used to help answering similar questions. 
- The reflection is generated using ground truth answers that will NOT be available when the playbook is being used. So you need to come up with content that can aid the playbook user to create predictions that likely align with ground truth.

CRITICAL: You MUST respond with valid JSON only. Do not use markdown formatting or code blocks.

Instructions: 
- Review the existing playbook and the reflection from the previous attempt 
- Identify ONLY the NEW insights, strategies, or mistakes that are MISSING from the current playbook 
- Avoid redundancy 
- if similar advice already exists, only add new content that is a perfect complement to the existing playbook 
- Do NOT regenerate the entire playbook 
- only provide the additions needed 
- Focus on quality over quantity 
- a focused, well-organized playbook is better than an exhaustive one 
- Format your response as a PURE JSON object with specific sections 
- For any operation if no new content to add, return an empty list for the operations field 
- Be concise and specific 
- each addition should be actionable

Training progress: {progress}
Playbook stats: {stats}

Recent reflection:
{reflection}

Current playbook:
{playbook}

Question context:
{question_context}

Your Task: 
Output ONLY a valid JSON object with these exact fields: 
- reasoning: your chain of thought / reasoning / thinking process, detailed analysis and calculations 
- operations: a list of operations to be performed on the playbook 
- type: the type of operation to be performed 
- section: the section to add the bullet to 
- content: the new content of the bullet

RESPONSE FORMAT - Output ONLY this JSON structure (no markdown, no code blocks):
{{
  "reasoning": "<Your chain of thought / reasoning / thinking process, detailed analysis and calculations here>",
  "operations": [
    {{
      "type": "ADD|UPDATE|TAG|REMOVE",
      "section": "<section name>",
      "content": "<bullet text>",
      "bullet_id": "<optional existing id>",
      "metadata": {{"helpful": 1, "harmful": 0}}
    }}
  ]
}}
If no updates are required, return an empty list for "operations".
"""
